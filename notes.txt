5.31

manual seed 41
in_features = 214, h1 = 40, h2 = 40, out_features=2
lr = 0.01
epochs = 100
407/748 correct - 0.5441176470588235

80, 80
376/748 correct - 0.5026737967914439

20, 20
409/748 correct - 0.5467914438502673

10, 10
399/748 correct - 0.5334224598930482

20, 20, 20
403/748 correct - 0.5387700534759359

40, 20, 10
430/748 correct - 0.5748663101604278

20, 20, 10
376/748 correct - 0.5026737967914439


80, 20, 10
376/748 correct - 0.5026737967914439

epochs -> 200
lr -> 0.02
40, 20, 10
426/748 correct - 0.56951871657754

epochs -> 500
419/748 correct - 0.5601604278074866

lr -> 0.03
epochs -> 1000
814/1496 correct - 0.5441176470588235

battle log = 123K battles
lr -> 0.001
epochs = 2000


epochs -> 100
lr -> 0.1
1397/2469 correct - 0.5658161198865937

epochs -> 200
1392/2469 correct - 0.5637910085054678

6.3
NEW INFO: Less epochs is better. There's already so much training data that it doesn't help to go back 
Also, when I run inference using example battles that should have obvious outcomes, it confidently answers wrongly.
    Could be some logic error that I made in my code.

